#:schema node_modules/wrangler/config-schema.json
name = "give-care-etl"
main = "src/index.ts"
compatibility_date = "2024-12-18"
node_compat = true

# Cloudflare Workers Configuration
workers_dev = true
account_id = "a900bd453c783129d31920f492a3ef1a"

# Durable Objects (persistent agents)
[[durable_objects.bindings]]
name = "ORCHESTRATOR_AGENT"
class_name = "OrchestratorAgent"

[[durable_objects.bindings]]
name = "DISCOVERY_AGENT"
class_name = "DiscoveryAgent"

[[durable_objects.bindings]]
name = "EXTRACTION_AGENT"
class_name = "ExtractionAgent"

[[durable_objects.bindings]]
name = "CATEGORIZER_AGENT"
class_name = "CategorizerAgent"

[[durable_objects.bindings]]
name = "VALIDATOR_AGENT"
class_name = "ValidatorAgent"

# Migrations for Durable Objects (free tier requires new_sqlite_classes)
[[migrations]]
tag = "v1"
new_sqlite_classes = ["OrchestratorAgent", "DiscoveryAgent", "ExtractionAgent", "CategorizerAgent", "ValidatorAgent"]

# Browser Rendering API (for Puppeteer)
browser = { binding = "BROWSER" }

# KV Namespaces (for caching and state)
[[kv_namespaces]]
binding = "ETL_STATE"
id = "dc1bc17743dd469eba022bb4b8d71571"

[[kv_namespaces]]
binding = "RESOURCE_CACHE"
id = "e5d1b5d4fc1043d6a4e47a8fa0dca546"

# D1 Database (optional - for local QA workflow)
# [[d1_databases]]
# binding = "DB"
# database_name = "give-care-etl-qa"
# database_id = ""

# Cron Triggers (weekly scraping)
[triggers]
crons = ["0 6 * * 1"] # Every Monday at 6am UTC

# Environment Variables (set via wrangler secret put)
[vars]
CONVEX_URL = "https://agreeable-lion-831.convex.cloud"
ENVIRONMENT = "development"

# No service bindings needed - agents imported directly from monorepo
# All agents are in src/agents/ and imported as modules

# Limits
limits = { cpu_ms = 50000 }
